{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c3ff69",
   "metadata": {},
   "source": [
    "### To setup the environment for downloading the dataset and the YOLOv5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "!pip install -r yolov5/requirements.txt\n",
    "!pip install roboflow\n",
    "\n",
    "import torch\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RtdzCZNW8mDA4ilAU416\")\n",
    "project = rf.workspace(\"projects-1vokb\").project(\"frogs-ft5yx\")\n",
    "dataset = project.version(1).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd2f92",
   "metadata": {},
   "source": [
    "### Train on polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/segment/train.py --data frogs-1/data.yaml --img 320 --epochs 10000 --batch 128 --name trained-seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce909c",
   "metadata": {},
   "source": [
    "### Test model on bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabffc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/segment/predict.py --save-txt --save-conf --weights yolov5/train-seg/trained-seg/weights/best.pt --img 320  --source 'frogs-1/test/images/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65550b2e",
   "metadata": {},
   "source": [
    "**Convert both the predicted polygons and the polygon test set from polygon to bounding box coordinates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0136a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from torchmetrics.classification import PrecisionRecallCurve\n",
    "import cv2\n",
    "\n",
    "def convert_to_bounding_box(segmentation_label):\n",
    "    x_coord, y_coord = [], []\n",
    "    for i in range(0, len(segmentation_label), 2):\n",
    "        x_coord.append(segmentation_label[i])\n",
    "        y_coord.append(segmentation_label[i+1])\n",
    "    return convert_to_yolov5(min(x_coord), min(y_coord), max(x_coord), max(y_coord))\n",
    "\n",
    "def convert_to_yolov5(xmin, ymin, xmax, ymax):\n",
    "    x_center = (xmin + xmax) / 2\n",
    "    y_center = (ymin + ymax) / 2\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    return np.array((x_center, y_center, width, height))\n",
    "\n",
    "\n",
    "def from_xmin_ymin_xmax_ymax_to_yolov5(folder_path, confidence=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            idx_to_delete = set()\n",
    "            for i, line in enumerate(lines):\n",
    "                values = line.split()\n",
    "                if len(values) < 6:\n",
    "                    idx_to_delete.add(i)\n",
    "                    continue\n",
    "                class_label = values[0]\n",
    "                if confidence:\n",
    "                    conf = values[-1]\n",
    "                    polygon = [float(val) for val in values[1:-1]]\n",
    "                    bbox = convert_to_bounding_box(polygon)\n",
    "                    lines[i] = ' '.join(map(str, bbox)) + str(\" \") + str(conf) + str(\" \") + str(class_label) + \"\\n\"\n",
    "                else:\n",
    "                    polygon = [float(val) for val in values[1:]]\n",
    "                    bbox = convert_to_bounding_box(polygon)\n",
    "                    lines[i] = f\"{class_label} {' '.join(map(str, bbox))}\"  + \"\\n\"\n",
    "            new_lines = []\n",
    "            for idx, line in enumerate(lines):\n",
    "                if idx not in idx_to_delete:\n",
    "                    new_lines.append(line)\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_folder = \"yolov5/runs/predict-seg/exp/labels/\" # predicted polygons\n",
    "gt_folder = \"frogs-1/test/labels/\" # ground truth polygons\n",
    "\n",
    "from_xmin_ymin_xmax_ymax_to_yolov5(preds_folder, confidence=True)\n",
    "from_xmin_ymin_xmax_ymax_to_yolov5(gt_folder, confidence=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d150d",
   "metadata": {},
   "source": [
    "### Compute metrics\n",
    "**Run this cell tu get the Precision, Recall and mAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set parameters for computing AP\n",
    "confidence_threshold = 0\n",
    "iou_threshold = 0\n",
    "\n",
    "# Initialize variables for computing precision, recall, and AP\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "total_gt_objects = 0\n",
    "c = 0\n",
    "\n",
    "# Loop through each file in gt folder\n",
    "for file_name in os.listdir(gt_folder):\n",
    "    c += 1\n",
    "    # Load ground truth data\n",
    "    gt_file_path = os.path.join(gt_folder, file_name)\n",
    "    with open(gt_file_path, \"r\") as f:\n",
    "        gt_data = f.readlines()\n",
    "    gt_data = [line.strip().split() for line in gt_data]\n",
    "\n",
    "    # Load prediction data\n",
    "    preds_file_path = os.path.join(preds_folder, file_name)\n",
    "    with open(preds_file_path, \"r\") as f:\n",
    "        preds_data = f.readlines()\n",
    "    preds_data = [line.strip().split() for line in preds_data]\n",
    "\n",
    "    # Initialize variables for computing recall and AP for this file\n",
    "    num_gt_objects = len(gt_data)\n",
    "    total_gt_objects += num_gt_objects\n",
    "    tp = [False] * num_gt_objects\n",
    "    fp = [False] * len(preds_data)\n",
    "    \n",
    "    # Loop through each prediction\n",
    "    for pred_idx, pred in enumerate(preds_data):\n",
    "        pred_x, pred_y, pred_w, pred_h, pred_conf, pred_class = pred\n",
    "        if pred_class == '-1':\n",
    "            pass\n",
    "        pred_x, pred_y, pred_w, pred_h, pred_conf = map(float, [pred_x, pred_y, pred_w, pred_h, pred_conf])\n",
    "        pred_conf = float(pred_conf)\n",
    "\n",
    "        # Find best matching ground truth object\n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "        for gt_idx, gt in enumerate(gt_data):\n",
    "            gt_class, gt_x, gt_y, gt_w, gt_h = gt\n",
    "            gt_x, gt_y, gt_w, gt_h = map(float, [gt_x, gt_y, gt_w, gt_h])\n",
    "\n",
    "            # Compute intersection over union (IOU)\n",
    "            x1 = max(gt_x - gt_w/2, pred_x - pred_w/2)\n",
    "            y1 = max(gt_y - gt_h/2, pred_y - pred_h/2)\n",
    "            x2 = min(gt_x + gt_w/2, pred_x + pred_w/2)\n",
    "            y2 = min(gt_y + gt_h/2, pred_y + pred_h/2)\n",
    "            intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "            union = gt_w * gt_h + pred_w * pred_h - intersection\n",
    "            iou = intersection / union\n",
    "\n",
    "            # Update best matching ground truth object if necessary\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = gt_idx\n",
    "        \n",
    "        # If IOU is above threshold and ground truth object has not been matched yet, count as true positive\n",
    "        if best_iou >= iou_threshold and not tp[best_gt_idx]:\n",
    "            if pred_conf >= confidence_threshold:\n",
    "                tp[best_gt_idx] = True\n",
    "            else:\n",
    "                fp[pred_idx] = True\n",
    "\n",
    "    # Add accumulated true positives and false positives to overall list\n",
    "    true_positives += tp\n",
    "    false_positives += fp\n",
    "\n",
    "# Compute precision, recall, and AP\n",
    "num_predictions = len(true_positives)\n",
    "cumulative_true_positives = [sum(true_positives[:i+1]) for i in range(num_predictions)]\n",
    "cumulative_false_positives = [sum(false_positives[:i+1]) for i in range(num_predictions)]\n",
    "\n",
    "precision = [0] * num_predictions\n",
    "recall = [0] * num_predictions\n",
    "ap = 0\n",
    "for i in range(num_predictions):\n",
    "    precision[i] = cumulative_true_positives[i] / (np.finfo(float).eps + cumulative_true_positives[i] + cumulative_false_positives[i])\n",
    "    recall[i] = cumulative_true_positives[i] / total_gt_objects\n",
    "    if recall[i] >= recall[i-1]:\n",
    "        ap += (recall[i] - recall[i-1]) * precision[i]\n",
    "\n",
    "print(\"Recall:\", recall[-1])\n",
    "print(\"Precision:\", precision[-1])\n",
    "print(\"mAP:\", ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996e248",
   "metadata": {},
   "source": [
    "### Train on bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --data frogs-1/data.yaml --img 320 --epochs 200 --batch 128 --name trained-od"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab008cad",
   "metadata": {},
   "source": [
    "### Computes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dde04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "preds_folder_od = \"yolov5/runs/detect/exp/labels/\"\n",
    "\n",
    "# Get list of file names in gt folder\n",
    "gt_files = os.listdir(gt_folder)\n",
    "\n",
    "# Loop through each file in gt folder\n",
    "for file_name in gt_files:\n",
    "    # Check if corresponding file exists in preds folder\n",
    "    preds_file_path = os.path.join(preds_folder_od, file_name)\n",
    "    if not os.path.exists(preds_file_path):\n",
    "        # Create file in preds folder with default values\n",
    "        with open(preds_file_path, \"w\") as f:\n",
    "            f.write(\"0 0 0 0 0 -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set parameters for computing AP\n",
    "confidence_threshold = 0\n",
    "iou_threshold = 0\n",
    "\n",
    "# Initialize variables for computing precision, recall, and AP\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "total_gt_objects = 0\n",
    "c = 0\n",
    "\n",
    "# Loop through each file in gt folder\n",
    "for file_name in os.listdir(gt_folder):\n",
    "    c += 1\n",
    "    # Load ground truth data\n",
    "    gt_file_path = os.path.join(gt_folder, file_name)\n",
    "    with open(gt_file_path, \"r\") as f:\n",
    "        gt_data = f.readlines()\n",
    "    gt_data = [line.strip().split() for line in gt_data]\n",
    "\n",
    "    # Load prediction data\n",
    "    preds_file_path = os.path.join(preds_folder, file_name)\n",
    "    with open(preds_file_path, \"r\") as f:\n",
    "        preds_data = f.readlines()\n",
    "    preds_data = [line.strip().split() for line in preds_data]\n",
    "\n",
    "    # Initialize variables for computing recall and AP for this file\n",
    "    num_gt_objects = len(gt_data)\n",
    "    total_gt_objects += num_gt_objects\n",
    "    tp = [False] * num_gt_objects\n",
    "    fp = [False] * len(preds_data)\n",
    "    \n",
    "    # Loop through each prediction\n",
    "    for pred_idx, pred in enumerate(preds_data):\n",
    "        pred_x, pred_y, pred_w, pred_h, pred_conf, pred_class = pred\n",
    "        if pred_class == '-1':\n",
    "            pass\n",
    "        pred_x, pred_y, pred_w, pred_h, pred_conf = map(float, [pred_x, pred_y, pred_w, pred_h, pred_conf])\n",
    "        pred_conf = float(pred_conf)\n",
    "\n",
    "        # Find best matching ground truth object\n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "        for gt_idx, gt in enumerate(gt_data):\n",
    "            gt_class, gt_x, gt_y, gt_w, gt_h = gt\n",
    "            gt_x, gt_y, gt_w, gt_h = map(float, [gt_x, gt_y, gt_w, gt_h])\n",
    "\n",
    "            # Compute intersection over union (IOU)\n",
    "            x1 = max(gt_x - gt_w/2, pred_x - pred_w/2)\n",
    "            y1 = max(gt_y - gt_h/2, pred_y - pred_h/2)\n",
    "            x2 = min(gt_x + gt_w/2, pred_x + pred_w/2)\n",
    "            y2 = min(gt_y + gt_h/2, pred_y + pred_h/2)\n",
    "            intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "            union = gt_w * gt_h + pred_w * pred_h - intersection\n",
    "            iou = intersection / union\n",
    "\n",
    "            # Update best matching ground truth object if necessary\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = gt_idx\n",
    "        \n",
    "        # If IOU is above threshold and ground truth object has not been matched yet, count as true positive\n",
    "        if best_iou >= iou_threshold and not tp[best_gt_idx]:\n",
    "            if pred_conf >= confidence_threshold:\n",
    "                tp[best_gt_idx] = True\n",
    "            else:\n",
    "                fp[pred_idx] = True\n",
    "\n",
    "    # Add accumulated true positives and false positives to overall list\n",
    "    true_positives += tp\n",
    "    false_positives += fp\n",
    "\n",
    "# Compute precision, recall, and AP\n",
    "num_predictions = len(true_positives)\n",
    "cumulative_true_positives = [sum(true_positives[:i+1]) for i in range(num_predictions)]\n",
    "cumulative_false_positives = [sum(false_positives[:i+1]) for i in range(num_predictions)]\n",
    "\n",
    "precision = [0] * num_predictions\n",
    "recall = [0] * num_predictions\n",
    "ap = 0\n",
    "for i in range(num_predictions):\n",
    "    precision[i] = cumulative_true_positives[i] / (np.finfo(float).eps + cumulative_true_positives[i] + cumulative_false_positives[i])\n",
    "    recall[i] = cumulative_true_positives[i] / total_gt_objects\n",
    "    if recall[i] >= recall[i-1]:\n",
    "        ap += (recall[i] - recall[i-1]) * precision[i]\n",
    "\n",
    "print(\"Recall:\", recall[-1])\n",
    "print(\"Precision:\", precision[-1])\n",
    "print(\"mAP:\", ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
