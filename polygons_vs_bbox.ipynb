{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c3ff69",
   "metadata": {},
   "source": [
    "### To setup the environment for downloading the dataset and the YOLOv5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "24ffc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Step2-v1_2-mud-illu-6-beixinyao-2 to yolov5pytorch: 100% [1236125028 / 1236125028] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Step2-v1_2-mud-illu-6-beixinyao-2 in yolov5pytorch:: 100%|████████████████████████████████████████| 5270/5270 [00:11<00:00, 477.66it/s]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "!pip install -r yolov5/requirements.txt\n",
    "!pip install roboflow\n",
    "\n",
    "import torch\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"<API_KEY\")\n",
    "project = rf.workspace(\"yolov7-twb3s\").project(\"step2-v1_2-mud-illu-6-beixinyao-vwcvx\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd2f92",
   "metadata": {},
   "source": [
    "### Train on polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/segment/train.py --data Step2-v1_2-mud-illu-6-beixinyao-2/data.yaml --img 320 --epochs 100 -- batch 128 --name trained-seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce909c",
   "metadata": {},
   "source": [
    "### Test model on bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabffc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/segment/predict.py --save-txt --weights yolov5/train-seg/trained-seg/weights/best.pt --img 320  --source 'Step2-v1_2-mud-illu-6-beixinyao-2/test/images/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65550b2e",
   "metadata": {},
   "source": [
    "**Convert both the predicted polygons and the polygon test set from polygon to bounding box coordinates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0136a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from torchmetrics.classification import PrecisionRecallCurve\n",
    "import cv2\n",
    "\n",
    "\n",
    "def convert_to_bounding_box(segmentation_label):\n",
    "    x_coord, y_coord = [], []\n",
    "    for i in range(0, len(segmentation_label), 2):\n",
    "        x_coord.append(segmentation_label[i])\n",
    "        y_coordinates.append(segmentation_label[i+1])\n",
    "    return convert_to_yolov5(min(x_coord), min(y_coord), max(x_coord), max(y_coord))\n",
    "\n",
    "def convert_to_yolov5(xmin, ymin, xmax, ymax):\n",
    "    x_center = (xmin + xmax) / 2\n",
    "    y_center = (ymin + ymax) / 2\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    return np.array((x_center, y_center, width, height))\n",
    "\n",
    "\n",
    "def from_xmin_ymin_xmax_ymax_to_yolov5(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                values = line.split()\n",
    "                class_label = values[0]\n",
    "                polygon = [float(val) for val in values[1:]]\n",
    "                bbox = convert_to_bounding_box(polygon)\n",
    "                lines[i] = f\"{class_label} {' '.join(map(str, bbox))}\\n\"\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(lines)\n",
    "                \n",
    "from_xmin_ymin_xmax_ymax_to_yolov5('yolov5/runs/predict-seg/exp/labels')\n",
    "from_xmin_ymin_xmax_ymax_to_yolov5('Step2-v1_2-mud-illu-6-beixinyao-2/test/labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d150d",
   "metadata": {},
   "source": [
    "### Compute metrics\n",
    "**Run this cell tu get the Precision, Recall and mAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523ffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) of two bounding boxes.\n",
    "    box1 and box2 are arrays of length 4: [x_center, y_center, width, height].\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    x_left = max(x1 - w1/2, x2 - w2/2)\n",
    "    y_top = max(y1 - h1/2, y2 - h2/2)\n",
    "    x_right = min(x1 + w1/2, x2 + w2/2)\n",
    "    y_bottom = min(y1 + h1/2, y2 + h2/2)\n",
    "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
    "    \n",
    "    # Calculate union area\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "\n",
    "def match_boxes(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    Matches boxes in boxes1 to boxes in boxes2 based on IoU.\n",
    "    boxes1 and boxes2 are arrays of shape (n_boxes, 5) where the first\n",
    "    element of each row is the class (0 or 1) and the remaining 4 elements\n",
    "    are [x_center, y_center, width, height].\n",
    "    Returns a list of tuples, where each tuple contains the indices of the\n",
    "    matched boxes in boxes1 and boxes2, or None if no match was found.\n",
    "    \"\"\"\n",
    "    n_boxes1 = boxes1.shape[0]\n",
    "    n_boxes2 = boxes2.shape[0]\n",
    "    \n",
    "    # Calculate IoU matrix\n",
    "    iou_matrix = np.zeros((n_boxes1, n_boxes2))\n",
    "    for i in range(n_boxes1):\n",
    "        for j in range(n_boxes2):\n",
    "            iou_matrix[i,j] = iou(boxes1[i], boxes2[j])\n",
    "    \n",
    "    # Find best matches\n",
    "    matches = []\n",
    "    \n",
    "    for i in range(n_boxes1):\n",
    "        j = np.argmax(iou_matrix[i])\n",
    "        if iou_matrix[i,j] > 0:\n",
    "            # Check if box j is already matched to another box\n",
    "            matched_boxes = [m[1] for m in matches if m is not None]\n",
    "            if j not in matched_boxes:\n",
    "                matches.append((i, j))\n",
    "            else:\n",
    "                # If box j is already matched, find the best unmatched box\n",
    "                ious = iou_matrix[i,:]\n",
    "                ious[matched_boxes] = 0\n",
    "                j2 = np.argmax(ious)\n",
    "                if iou_matrix[i,j2] >= 0.5:\n",
    "                    matches.append((i, j2))\n",
    "    return matches\n",
    "\n",
    "def compute_recall(pred_boxes, pred_classes, pred_confidence, gt_boxes, gt_classes, iou_threshold=0.5, confidence_threshold=0.5):\n",
    "    # Filter predicted boxes based on confidence score\n",
    "    positive_mask = pred_confidence >= confidence_threshold\n",
    "    pred_boxes = pred_boxes[positive_mask]\n",
    "    pred_classes = pred_classes[positive_mask]\n",
    "\n",
    "    # Compute IoU between predicted boxes and ground truth boxes\n",
    "    iou_matrix = pairwise_distances(pred_boxes, gt_boxes, metric=iou)\n",
    "    matches = iou_matrix > iou_threshold\n",
    "\n",
    "    # Count true positives for each ground truth box\n",
    "    tp_counts = np.sum(matches, axis=0)\n",
    "    tp_mask = tp_counts > 0\n",
    "\n",
    "    # Compute recall\n",
    "    recall = np.sum(tp_mask) / gt_boxes.shape[0]\n",
    "\n",
    "    return recall\n",
    "\n",
    "def compute_precision(pred_boxes, pred_classes, pred_confidence, gt_boxes, gt_classes, iou_threshold=0.5, confidence_threshold=0.5):\n",
    "    # Filter predicted boxes based on confidence score\n",
    "    positive_mask = pred_confidence >= confidence_threshold\n",
    "    pred_boxes = pred_boxes[positive_mask]\n",
    "    pred_classes = pred_classes[positive_mask]\n",
    "\n",
    "    # Compute IoU between predicted boxes and ground truth boxes\n",
    "    iou_matrix = pairwise_distances(pred_boxes, gt_boxes, metric=iou)\n",
    "    matches = iou_matrix > iou_threshold\n",
    "\n",
    "    # Count true positives for each predicted box\n",
    "    tp_counts = np.sum(matches, axis=1)\n",
    "    tp_mask = tp_counts > 0\n",
    "\n",
    "    # Compute precision\n",
    "    precision = np.sum(tp_mask) / pred_boxes.shape[0]\n",
    "\n",
    "    return precision\n",
    "\n",
    "# folder path containing txt files\n",
    "folder_path = \"yolov5/runs/predict-seg/exp/labels/\"\n",
    "folder_path_test = \"Step2-v1_2-mud-illu-6-beixinyao-2/test/labels/\"\n",
    "mAP, p, r = 0, 0, 0\n",
    "how_many = 0\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    how_many += 1\n",
    "    preds_ann = {'boxes':[], 'scores':[], 'labels':[]}\n",
    "    with open(os.path.join(folder_path, filename), \"r\") as file:\n",
    "        for line in file:\n",
    "            values = [float(value) for value in line.strip().split()]\n",
    "            bbox = convert_to_bounding_box(values[1:-1])\n",
    "            class_obj = int(values[0])\n",
    "            confidence = values[-1]\n",
    "            preds_ann['boxes'].append(bbox)\n",
    "            preds_ann['scores'].append(confidence)\n",
    "            preds_ann['labels'].append(class_obj)\n",
    "    preds = [dict(boxes=preds_ann['boxes'], scores=preds_ann['scores'], labels=preds_ann['labels'])]\n",
    "    \n",
    "    target_ann = {'boxes':[], 'labels':[]}\n",
    "    with open(os.path.join(folder_path_test, filename), \"r\") as file:\n",
    "            for line in file:\n",
    "                values = [float(value) for value in line.strip().split()]\n",
    "                class_obj = int(values[0])\n",
    "                target_ann['boxes'].append(values[1:])\n",
    "                target_ann['labels'].append(class_obj)    \n",
    "    target = [dict(boxes=target_ann['boxes'], labels=target_ann['labels'])]\n",
    "    \n",
    "    # box matching\n",
    "    matches = match_boxes(np.array(target[0]['boxes']), np.array(preds[0]['boxes']))\n",
    "    \n",
    "    # swap\n",
    "    for i in range(len(matches)):\n",
    "        preds[0]['boxes'][matches[i][1]] = target[0]['boxes'][matches[i][0]]\n",
    "        preds[0]['labels'][matches[i][1]] = target[0]['labels'][matches[i][0]]\n",
    "    \n",
    "    preds[0]['boxes'] = torch.from_numpy(np.array(preds[0]['boxes']))\n",
    "    preds[0]['scores'] = torch.from_numpy(np.array(preds[0]['scores']))\n",
    "    preds[0]['labels'] = torch.from_numpy(np.array(preds[0]['labels']))\n",
    "\n",
    "    target[0]['boxes'] = torch.from_numpy(np.array(target[0]['boxes']))\n",
    "    target[0]['labels'] = torch.from_numpy(np.array(target[0]['labels']))\n",
    "    \n",
    "    # compute metrics\n",
    "    metric = MeanAveragePrecision(box_format='cxcywh')\n",
    "    metric.update(preds, target)\n",
    "    mAP += metric.compute()['map'].item()\n",
    "    r += compute_recall(preds[0]['boxes'], preds[0]['labels'], preds[0]['scores'], target[0]['boxes'], target[0]['labels'])\n",
    "    p += compute_precision(preds[0]['boxes'], preds[0]['labels'], preds[0]['scores'], target[0]['boxes'], target[0]['labels'])\n",
    "                       \n",
    "print('Precision: {}, Recall: {}, mAP: {}'.format(p/how_many, r/how_many, mAP/how_many))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996e248",
   "metadata": {},
   "source": [
    "### Train on bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --data Step2-v1_2-mud-illu-6-beixinyao-2/data.yaml --img 320 --epochs 100 -- batch 128 --name trained-od"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab008cad",
   "metadata": {},
   "source": [
    "### Computes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3dde04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=Step2-v1_2-mud-illu-6-beixinyao-2/data.yaml, weights=['OD/trained_on_bbox/train/bestOD.pt'], batch_size=32, imgsz=320, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-105-g226a5e4 Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/pptr/Desktop/roboflow/Step2-v1_2-mud-illu-6-beixinyao-2/vali\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/pptr/Desktop/roboflow/Step2-v1_2-mud-illu-6-beixinyao-2/valid/labels.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         51        939      0.977      0.947      0.981      0.773\n",
      "                  coal         51        308      0.986      0.977      0.994      0.806\n",
      "                  rock         51        631      0.968      0.916      0.968      0.741\n",
      "Speed: 1.7ms pre-process, 83.2ms inference, 1.7ms NMS per image at shape (32, 3, 320, 320)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp76\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --weights OD/trained_on_bbox/train/bestOD.pt --img 320 --data Step2-v1_2-mud-illu-6-beixinyao-2/data.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
